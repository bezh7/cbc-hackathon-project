# ğŸ“Š Financial Document Analyzer

An AI-powered tool for analyzing 10-K financial filings using GPT-4o-mini Vision, RAG (Retrieval Augmented Generation), and MongoDB persistence.

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸŒŸ Features

- **ğŸ” Smart Table Detection** - LLM-powered filtering to identify only financial tables (filters out TOC, exhibits, etc.)
- **ğŸ‘ï¸ Vision-Based Metric Extraction** - GPT-4o-mini Vision reads complex tables and charts
- **ğŸ¤– AI Financial Analysis** - Automated generation of insights, trends, and risk flags
- **ğŸ’¬ RAG-Powered Chat** - Ask questions about the entire document with source citations
- **ğŸ“Š MongoDB Persistence** - Store and query structured financial data across multiple filings
- **ğŸ“ˆ Time Series Support** - Track metrics across multiple years and quarters

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ frontend/              # Streamlit UI
â”‚   â””â”€â”€ app.py            # Main application
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/             # Core business logic
â”‚   â”‚   â”œâ”€â”€ models.py     # Data models (Pydantic)
â”‚   â”‚   â”œâ”€â”€ ingestion.py  # PDF processing & table detection
â”‚   â”‚   â”œâ”€â”€ vlm_client.py # GPT-4o-mini Vision extraction
â”‚   â”‚   â””â”€â”€ llm_analysis.py # GPT analysis & RAG chat
â”‚   â”œâ”€â”€ rag/              # RAG system
â”‚   â”‚   â”œâ”€â”€ rag_chunking.py  # Text chunking with token counting
â”‚   â”‚   â””â”€â”€ rag_retrieval.py # In-memory vector search
â”‚   â””â”€â”€ database/         # MongoDB integration
â”‚       â”œâ”€â”€ mongo_client.py  # Connection helper
â”‚       â””â”€â”€ persistence.py   # CRUD operations
â”œâ”€â”€ docs/                 # Documentation
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- OpenAI API key
- MongoDB Atlas account (free tier works)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/financial-document-analyzer.git
   cd financial-document-analyzer
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your API keys
   ```

4. **Run the application**
   ```bash
   streamlit run frontend/app.py
   ```

5. **Open in browser**
   - Navigate to `http://localhost:8501`

## ğŸ“ Configuration

Create a `.env` file in the project root:

```bash
# Required
OPENAI_API_KEY=your_openai_api_key_here

# MongoDB (optional - for persistence)
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/
MONGODB_DB_NAME=financial_analyzer
```

## ğŸ’» Usage

### 1. Upload & Analyze
- Upload a 10-K PDF
- Enter company information (name, ticker, fiscal year)
- Click "Analyze Document"

### 2. View Results
- **Extracted Metrics** - Revenue, Net Income, Assets, etc. with multi-period values
- **Key Signals** - Important trends and growth patterns
- **Risk Flags** - Concerns and red flags identified by AI
- **Summary** - Overall financial situation

### 3. Chat with Document
- Ask questions like:
  - "What are the main risk factors?"
  - "How did revenue change year-over-year?"
  - "What does management say about future outlook?"
- Get answers with **source page citations**

### 4. Save to Database (Optional)
- Click "Save to Database" to persist metrics
- View recent filings and metrics in the database preview

## ğŸ”§ How It Works

### Analysis Pipeline

```
PDF Upload
    â†“
[1. Ingestion] â†’ Smart table detection with LLM filtering
    â†“
[2. Vision Extraction] â†’ GPT-4o-mini reads tables â†’ Structured metrics
    â†“
[3. Text Chunking] â†’ Section-aware chunking (~500 tokens)
    â†“
[4. Embedding] â†’ OpenAI embeddings (text-embedding-3-small)
    â†“
[5. Analysis] â†’ GPT generates insights
    â†“
Results + RAG Chat
```

### Chat/Query Flow

```
User Question
    â†“
[1. Embed Query] â†’ text-embedding-3-small
    â†“
[2. Semantic Search] â†’ Cosine similarity (top-2 chunks)
    â†“
[3. Context Building] â†’ Metrics + Chunks + Report
    â†“
[4. LLM Response] â†’ GPT-4o-mini with grounded context
    â†“
Answer + Source Pages
```

## ğŸ“Š Database Schema

### Collections

**filings**
```json
{
  "filing_id": "uuid",
  "company": "Apple Inc.",
  "ticker": "AAPL",
  "year": 2023,
  "filename": "AAPL_10K_2023.pdf",
  "uploaded_at": "2024-01-15T10:30:00Z"
}
```

**metrics**
```json
{
  "metric_id": "uuid",
  "filing_id": "uuid",
  "name": "Revenue",
  "period": "2023",
  "value": 394328000000,
  "source_pages": [42, 43],
  "extracted_at": "2024-01-15T10:35:00Z"
}
```

## ğŸ’° Cost Estimates

Per document analysis (~200 pages):
- PDF ingestion: Free
- VLM extraction (3-5 pages): ~$0.01
- Text chunking: Free
- Embeddings (~100 chunks): ~$0.0002
- GPT analysis: ~$0.001
- **Total: ~$0.011 per document**

Per chat query: ~$0.001

## ğŸ› ï¸ Development

### Project Structure

- `frontend/` - Streamlit UI layer
- `backend/core/` - Business logic (ingestion, extraction, analysis)
- `backend/rag/` - RAG implementation (chunking, retrieval)
- `backend/database/` - MongoDB persistence layer
- `docs/` - Documentation and guides

### Running Tests

```bash
python -m pytest tests/
```

### Code Style

```bash
# Format code
black .

# Lint
flake8 .
```

## ğŸ› Troubleshooting

### MongoDB Connection Issues
- Ensure your IP is whitelisted in MongoDB Atlas Network Access
- Check connection string format
- Verify username/password

### Rate Limit Errors
- The app has automatic retry logic with exponential backoff
- If persistent, upgrade your OpenAI plan or reduce batch sizes

### Import Errors
- Make sure you're running from the project root
- Check that all dependencies are installed: `pip install -r requirements.txt`

## ğŸ“š Documentation

- [RAG Implementation Guide](RAG_IMPLEMENTATION.md)
- [Database Schema](docs/database-schema.md)
- [API Documentation](docs/api.md)

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT-4o-mini and embeddings API
- Streamlit for the amazing UI framework
- PyMuPDF for PDF processing capabilities
